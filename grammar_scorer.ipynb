{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This system predicts grammatical quality by analyzing audio and text. First, Whisper converts audio into text, which is then processed for cleaning (language detection, normalization). Poor-quality text results in reliance on audio features alone. RoBERTa extracts text features (last layers fine-tuned), and Whisper extracts robust audio features, capturing voice nuances. These features are combined and fed into a neural network (HybridGrammarScorer). The model is trained on 80% of the data, validated on 20%, optimizing for Pearson correlation. Audio enriches context and handles noisy data. The best model predicts grammatical quality for test data, with results adjusted for realistic output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Grammatical Quality Prediction**\n",
    "\n",
    "Our goal is to accurately assess the grammatical quality of spoken language. To achieve this, we've designed a multimodal pipeline that leverages both textual and audio features.\n",
    "\n",
    "**Pipeline Stages:**\n",
    "\n",
    "**Audio to Text Conversion (Whisper):**\n",
    "\n",
    "The initial stage involves transcribing the audio input using OpenAI's Whisper model. This provides us with a textual representation of the spoken language.\n",
    "It is noted that the quality of these transcripts can vary significantly, with some containing multiple languages, minimal coherent text, or considerable noise.\n",
    "\n",
    "**Text Preprocessing:**\n",
    "\n",
    "The transcribed text undergoes preprocessing to enhance its quality. This includes:\n",
    "* Language detection to identify if it is English.\n",
    "* Regular expression cleaning to remove unwanted characters and noise.\n",
    "* spaCy-based normalization to standardize text (e.g., lemmatization, tokenization).\n",
    "* The transcribed text undergoes cleaning and normalization. Crucially, if the preprocessing reveals the text is not up to the mark—for example, it's not in English, contains very little information, or has excessive noise—the system returns an empty text output, recognizing that text features will be unreliable.\n",
    "\n",
    "**Feature Extraction:**\n",
    "\n",
    "*Text Features (RoBERTa):*\n",
    "\n",
    "For high-quality text, we extract features using a pretrained RoBERTa model.\n",
    "To balance performance and computational efficiency, we fine-tune only the last two layers of the RoBERTa encoder.\n",
    "\n",
    "*Audio Features (Whisper):*\n",
    "\n",
    "* Regardless of text quality, we extract audio features using the Whisper model.\n",
    "* Audio features enhance grammar prediction by capturing intonation, pronunciation, and voice quality, providing context and robustness beyond text. They are especially valuable when text quality is poor.\n",
    "*Feature Combination:*\n",
    "If the text is of good quality, the text and audio embeddings are concatenated.\n",
    "if the text is of bad quality, only the audio embeddings are used.\n",
    "\n",
    "\n",
    "**Model Training and Validation (HybridGrammarScorer):**\n",
    "\n",
    "* The combined (or audio-only) features are fed into our hybrid model, HybridGrammarScorer, which consists of several fully connected layers.\n",
    "* The model is trained to predict a regression score representing grammatical quality.\n",
    "* The dataset is split into 80% training data and 20% validation data.\n",
    "* The model is trained using Mean Squared Error (MSE) loss and the Adam optimizer.\n",
    "* The model's performance is evaluated using metrics like Pearson correlation, MSE, MAE, and R².\n",
    "* The model with the best validation Pearson correlation is selected and saved.\n",
    "**Test Set Prediction:**\n",
    "\n",
    "* For the test set, we apply the same preprocessing and feature extraction steps.\n",
    "* The trained HybridGrammarScorer model generates predictions.\n",
    "* The final predictions are saved into a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1261.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_942.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1110.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1024.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_538.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_350.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_64.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_252.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1304.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1230.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_133.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_790.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_947.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_288.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1111.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_771.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1184.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_918.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1030.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1112.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_873.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_539.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_899.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1277.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_649.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_701.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_763.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_952.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_167.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_708.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1245.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_812.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_76.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1296.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_239.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_668.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_17.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_289.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_45.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_657.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_876.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1069.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1318.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_832.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_917.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_802.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_275.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_940.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1120.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_535.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_244.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1134.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_724.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_965.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1031.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1326.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1325.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_273.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1298.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_868.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_964.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_85.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_919.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_303.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_345.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_930.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_817.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1104.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_836.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_946.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1312.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_324.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_913.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_399.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_766.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_748.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1114.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1251.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_59.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_889.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_130.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_297.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_744.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_779.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1210.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_680.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_944.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_8.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1057.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_722.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1036.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_760.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_675.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_62.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_865.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_654.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_743.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_950.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_77.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_916.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1028.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_727.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_146.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_642.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1313.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1208.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_640.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_778.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1025.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_939.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1216.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_934.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_904.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1102.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1150.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_765.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1117.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_685.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1329.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_236.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_90.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_903.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_905.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_736.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_886.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_773.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_43.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_853.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_278.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_948.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_869.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1223.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1038.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_686.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_346.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_988.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_653.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_809.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1043.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_542.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1106.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_643.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1333.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1239.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1264.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_854.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_681.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_711.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_5.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_446.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_827.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_67.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_776.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_93.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_677.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1226.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1136.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_536.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1247.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_61.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_336.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_661.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_788.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1212.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_813.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1118.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_678.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_427.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_755.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_110.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_859.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_957.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1252.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1126.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_699.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1314.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_794.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1129.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_808.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_875.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_842.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1182.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_848.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1040.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_956.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_902.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_441.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_237.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1290.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1162.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_700.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1200.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_147.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_212.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_168.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_240.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_695.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_256.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_443.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_63.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_721.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_636.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_870.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1335.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_707.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_581.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_272.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1284.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1135.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1187.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_480.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_445.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_447.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1191.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1266.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1307.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_270.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1032.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_931.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_71.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_482.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_725.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_301.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_184.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_387.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_730.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_980.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_602.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_874.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1148.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_954.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_185.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_12.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_241.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_697.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_548.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1128.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_582.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_925.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_69.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_896.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_7.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_611.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_82.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_591.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_674.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_753.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_131.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1103.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_961.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_188.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_926.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_921.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_955.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_127.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_327.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_485.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_705.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1147.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_468.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_477.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_395.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1065.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_254.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1017.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1196.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_358.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_716.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1236.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_807.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_490.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_492.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_469.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_890.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_600.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_731.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_339.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_909.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_658.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_117.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1082.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_291.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1066.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_630.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_404.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_334.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_33.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_186.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_693.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_937.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_424.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1262.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_624.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_620.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_142.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_259.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_503.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1125.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1332.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_52.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_558.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_223.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_194.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_362.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1153.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_200.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_479.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_455.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_313.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_15.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1100.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_80.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_887.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_105.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_483.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_796.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_2.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_317.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_963.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_123.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1272.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_315.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1202.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1008.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_787.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1274.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_265.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1268.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_526.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1285.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_460.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_696.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_44.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_478.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_450.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1164.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_245.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_255.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_513.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_504.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_590.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_592.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_389.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_353.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_250.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_432.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_583.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_402.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_312.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_493.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_516.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_373.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_119.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1175.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1160.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_102.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_140.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_205.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_414.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_314.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_374.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1177.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_464.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_518.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_352.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_396.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_332.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_495.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_53.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_463.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_970.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_120.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_293.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_688.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_834.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_440.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_116.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_359.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_74.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_154.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_32.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_413.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1075.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_163.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1171.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_745.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_527.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_202.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_533.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_226.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_552.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_978.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_994.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_365.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1185.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_826.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_860.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_23.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_144.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_586.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_489.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_694.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_704.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_783.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1059.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_549.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_627.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_311.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_118.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_462.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_419.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_983.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1172.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_436.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_687.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_514.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_484.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1131.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_55.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_547.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_652.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_703.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_9.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_563.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1078.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_758.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_647.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_867.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_567.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_471.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_576.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_210.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_993.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_390.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_104.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_366.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_990.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1099.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_609.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_494.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_363.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_481.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_989.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train/audio_1163.wav...\n",
      "Transcription complete. CSV saved to /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/train_with_transcripts.csv.\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_706.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_800.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_68.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1267.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_683.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1242.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_908.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_888.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_137.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_770.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_735.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1026.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1214.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1122.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1022.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_726.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1205.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1116.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1240.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_151.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_437.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1217.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_831.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1315.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1323.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1256.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1033.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_858.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_274.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_196.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1193.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_138.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_644.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1012.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1101.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_805.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_709.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1293.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1123.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1048.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_820.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_767.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_841.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1286.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_665.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1311.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_29.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1289.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_177.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_599.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_920.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_971.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1275.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1291.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_320.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_545.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_287.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_172.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_322.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_541.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_148.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1317.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1243.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_348.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_662.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_540.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_733.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1297.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_949.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1035.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_882.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_401.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_113.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_435.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_719.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_698.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_959.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1166.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_543.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_89.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_884.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_19.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_641.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1115.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_811.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_75.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1138.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_66.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_500.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_922.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_656.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_218.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1278.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_525.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_290.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1195.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_572.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1089.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_488.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_759.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_103.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1280.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_153.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_300.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_20.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_10.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1292.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_281.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_261.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1081.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_276.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_159.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1124.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_690.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1061.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_521.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_263.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1068.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_4.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_676.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_165.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_282.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1179.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_217.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_388.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_550.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_499.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1190.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_433.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_885.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_48.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_308.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_746.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1019.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_487.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_198.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_958.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_72.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1321.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1159.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_428.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1058.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_408.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_857.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_692.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_633.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1173.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_554.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_180.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1013.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_386.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_519.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_564.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1054.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_556.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1183.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_306.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_713.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_225.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1091.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_107.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_286.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_546.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_580.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_235.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_109.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_932.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_330.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_569.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_158.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_321.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_360.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_391.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_448.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1215.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_422.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_998.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_702.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_897.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_394.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1169.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_95.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_604.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_221.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_34.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_179.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_21.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1176.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_285.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_1178.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_135.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_512.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_529.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_762.wav...\n",
      "Processing /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test/audio_379.wav...\n",
      "Transcription complete. CSV saved to /home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/test_with_transcripts.csv.\n"
     ]
    }
   ],
   "source": [
    "    import os\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import torchaudio\n",
    "    from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "    # Set device: use GPU if available, otherwise CPU.\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # =======================================\n",
    "    # Load the processor and model (for conditional generation).\n",
    "    whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "    whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device)\n",
    "    whisper_model.eval()\n",
    "\n",
    "def process_dataset(csv_path, audio_folder, output_csv_path):\n",
    "    \"\"\"\n",
    "    Process audio files listed in the CSV file, generate transcriptions using the Whisper model,\n",
    "    and save a new CSV with an added 'text' column containing the transcriptions.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file containing filenames.\n",
    "        audio_folder (str): Directory where the audio files are stored.\n",
    "        output_csv_path (str): Path where the new CSV file with transcripts will be saved.\n",
    "    \"\"\"\n",
    "    # Read the CSV file.\n",
    "    df = pd.read_csv(csv_path)\n",
    "    transcripts = []\n",
    "\n",
    "    # Process each audio file in the CSV.\n",
    "    for filename in df[\"filename\"]:\n",
    "        audio_path = os.path.join(audio_folder, filename)\n",
    "        print(f\"Processing {audio_path}...\")\n",
    "        \n",
    "        # Load the audio file using torchaudio.\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        \n",
    "        # If the audio has multiple channels, convert it to mono by averaging.\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        \n",
    "        # Resample if necessary (Whisper expects a 16kHz sample rate).\n",
    "        if sr != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
    "            waveform = resampler(waveform)\n",
    "            sr = 16000\n",
    "        \n",
    "        # Process the waveform into input features.\n",
    "        input_features = whisper_processor(\n",
    "            audio=waveform.squeeze().numpy(),\n",
    "            sampling_rate=sr,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_features.to(device)\n",
    "        \n",
    "        # Generate predictions using the model.\n",
    "        predicted_ids = whisper_model.generate(input_features)\n",
    "        \n",
    "        # Decode the predictions to text.\n",
    "        transcription = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
    "        transcripts.append(transcription)\n",
    "    \n",
    "    # Add the transcripts as a new column in the DataFrame.\n",
    "    df[\"text\"] = transcripts\n",
    "    \n",
    "    # Save the updated DataFrame to a new CSV file.\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Transcription complete. CSV saved to {output_csv_path}.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Process the train dataset.\n",
    "train_csv_path = \"/home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/train.csv\"\n",
    "train_audio_folder = \"/home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_train\"\n",
    "train_output_csv_path = os.path.join(os.path.dirname(train_csv_path), \"train_with_transcripts.csv\")\n",
    "process_dataset(train_csv_path, train_audio_folder, train_output_csv_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Process the test dataset.\n",
    "test_csv_path = \"/home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/test.csv\"\n",
    "test_audio_folder = \"/home/ankur/ASR_Meta/VLM/TTS/grammar/dataset/audios_test\"\n",
    "test_output_csv_path = os.path.join(os.path.dirname(test_csv_path), \"test_with_transcripts.csv\")\n",
    "process_dataset(test_csv_path, test_audio_folder, test_output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ankur/ASR_Meta/VLM/TTS/env_TTS/lib/python3.8/site-packages (from langdetect) (1.17.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=7d98877889e49789946d80f5df63fafd66e2db0e80d3e628065238881cb02467\n",
      "  Stored in directory: /home/ankur/.cache/pip/wheels/13/c7/b0/79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "from langdetect import detect, LangDetectException\n",
    "import os\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Error loading spaCy model. Please ensure it's downloaded.\")\n",
    "    raise\n",
    "\n",
    "TARGET_LANGUAGE = \"en\"\n",
    "MIN_WORD_COUNT = 3\n",
    "\n",
    "def is_target_language(text, target_lang=TARGET_LANGUAGE):\n",
    "    try:\n",
    "        return detect(text) == target_lang\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "\n",
    "def has_noise(text):\n",
    "    if re.search(r\"[^\\x00-\\x7F]\", text):  # Non-ASCII\n",
    "        return True\n",
    "    if re.search(r\"([^a-zA-Z0-9\\s])\\1{1,}\", text):  # Repeated punctuation\n",
    "        return True\n",
    "    if len(text.strip().split()) < MIN_WORD_COUNT:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize(\"NFKD\", text).lower()\n",
    "\n",
    "def remove_noise(text):\n",
    "    text = re.sub(r\"([^a-zA-Z0-9\\s])\\1+\", r\"\\1\", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "def clean_text_with_spacy(text):\n",
    "    text = normalize_text(text)\n",
    "    text = remove_noise(text)\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([\n",
    "        token.lemma_ for token in doc\n",
    "        if not token.is_stop and token.is_alpha and len(token) > 1\n",
    "    ])\n",
    "\n",
    "def process_transcripts(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cleaned_texts = []\n",
    "\n",
    "    for text in df[\"text\"]:\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            cleaned_texts.append(\"\")\n",
    "            continue\n",
    "\n",
    "        if not is_target_language(text):\n",
    "            cleaned_texts.append(\"\")\n",
    "            continue\n",
    "\n",
    "        if has_noise(text):\n",
    "            cleaned_text = clean_text_with_spacy(text)\n",
    "            cleaned_texts.append(cleaned_text)\n",
    "        else:\n",
    "            cleaned_texts.append(text.strip())\n",
    "\n",
    "    df[\"cleaned_text\"] = cleaned_texts\n",
    "\n",
    "    # Return appropriate columns\n",
    "    base_columns = [\"filename\", \"text\", \"cleaned_text\"]\n",
    "    if \"label\" in df.columns:\n",
    "        base_columns.insert(1, \"label\")  # Insert label after filename\n",
    "\n",
    "    return df[base_columns]\n",
    "\n",
    "def save_cleaned_csv(df, original_csv_path, suffix=\"_cleaned_filtered\"):\n",
    "    directory = os.path.dirname(original_csv_path)\n",
    "    basename = os.path.basename(original_csv_path)\n",
    "    name, ext = os.path.splitext(basename)\n",
    "    output_path = os.path.join(directory, f\"{name}{suffix}{ext}\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Cleaned CSV saved to {output_path}\")\n",
    "\n",
    "def clean_and_save_dataset(csv_path):\n",
    "    df = process_transcripts(csv_path)\n",
    "    save_cleaned_csv(df, csv_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_csv_path = \"train_with_transcripts.csv\"\n",
    "    test_csv_path = \"test_with_transcripts.csv\"\n",
    "\n",
    "    clean_and_save_dataset(train_csv_path)\n",
    "    clean_and_save_dataset(test_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-04-07 02:33:30,057 - Failed audio files during dataset creation: 0\n",
      "2025-04-07 02:33:30,058 - Training started at 2025-04-07 02:33:30\n",
      "2025-04-07 02:33:30,059 - Training parameters: BATCH_SIZE=8, EPOCHS=50\n",
      "2025-04-07 02:33:30,060 - Label stats: Mean=3.64, Std=1.10\n",
      "2025-04-07 02:34:35,958 -                                                       \n",
      " Epoch 1\n",
      "2025-04-07 02:34:35,960 -    Pearson: 0.7208  MSE: 0.7258  MAE: 0.6973  R²: 0.4676  Train Loss: 0.8154\n",
      "2025-04-07 02:34:37,717 -     Saved best model\n",
      "2025-04-07 02:35:42,921 -                                                       \n",
      " Epoch 2\n",
      "2025-04-07 02:35:42,924 -    Pearson: 0.7398  MSE: 0.7265  MAE: 0.6992  R²: 0.4671  Train Loss: 0.4117\n",
      "2025-04-07 02:35:44,773 -     Saved best model\n",
      "2025-04-07 02:36:49,599 -                                                        \n",
      " Epoch 3\n",
      "2025-04-07 02:36:49,600 -    Pearson: 0.6909  MSE: 0.7496  MAE: 0.6754  R²: 0.4501  Train Loss: 0.3519\n",
      "2025-04-07 02:37:55,375 -                                                        \n",
      " Epoch 4\n",
      "2025-04-07 02:37:55,376 -    Pearson: 0.7367  MSE: 0.7356  MAE: 0.6467  R²: 0.4604  Train Loss: 0.2604\n",
      "2025-04-07 02:39:01,527 -                                                         \n",
      " Epoch 5\n",
      "2025-04-07 02:39:01,528 -    Pearson: 0.7459  MSE: 0.6654  MAE: 0.6526  R²: 0.5119  Train Loss: 0.1570\n",
      "2025-04-07 02:39:03,431 -     Saved best model\n",
      "2025-04-07 02:40:09,240 -                                                        \n",
      " Epoch 6\n",
      "2025-04-07 02:40:09,242 -    Pearson: 0.7133  MSE: 0.6725  MAE: 0.6420  R²: 0.5067  Train Loss: 0.1263\n",
      "2025-04-07 02:41:14,319 -                                                        \n",
      " Epoch 7\n",
      "2025-04-07 02:41:14,320 -    Pearson: 0.7192  MSE: 0.6822  MAE: 0.6613  R²: 0.4995  Train Loss: 0.1103\n",
      "2025-04-07 02:42:20,687 -                                                        \n",
      " Epoch 8\n",
      "2025-04-07 02:42:20,689 -    Pearson: 0.7124  MSE: 0.6720  MAE: 0.6472  R²: 0.5070  Train Loss: 0.1072\n",
      "2025-04-07 02:43:26,942 -                                                        \n",
      " Epoch 9\n",
      "2025-04-07 02:43:26,945 -    Pearson: 0.7106  MSE: 0.6769  MAE: 0.6425  R²: 0.5034  Train Loss: 0.0886\n",
      "2025-04-07 02:44:34,361 -                                                         \n",
      " Epoch 10\n",
      "2025-04-07 02:44:34,363 -    Pearson: 0.7433  MSE: 0.6160  MAE: 0.6267  R²: 0.5481  Train Loss: 0.0770\n",
      "2025-04-07 02:45:40,688 -                                                          \n",
      " Epoch 11\n",
      "2025-04-07 02:45:40,690 -    Pearson: 0.7285  MSE: 0.6413  MAE: 0.6217  R²: 0.5295  Train Loss: 0.0692\n",
      "2025-04-07 02:46:52,205 -                                                          \n",
      " Epoch 12\n",
      "2025-04-07 02:46:52,207 -    Pearson: 0.7290  MSE: 0.6458  MAE: 0.6517  R²: 0.5262  Train Loss: 0.0640\n",
      "2025-04-07 02:47:59,309 -                                                          \n",
      " Epoch 13\n",
      "2025-04-07 02:47:59,312 -    Pearson: 0.7432  MSE: 0.6143  MAE: 0.6312  R²: 0.5493  Train Loss: 0.0622\n",
      "2025-04-07 02:49:05,991 -                                                          \n",
      " Epoch 14\n",
      "2025-04-07 02:49:05,993 -    Pearson: 0.7393  MSE: 0.6211  MAE: 0.6348  R²: 0.5444  Train Loss: 0.0485\n",
      "2025-04-07 02:50:14,346 -                                                          \n",
      " Epoch 15\n",
      "2025-04-07 02:50:14,350 -    Pearson: 0.7224  MSE: 0.6702  MAE: 0.6456  R²: 0.5084  Train Loss: 0.0471\n",
      "2025-04-07 02:51:23,504 -                                                          \n",
      " Epoch 16\n",
      "2025-04-07 02:51:23,505 -    Pearson: 0.7406  MSE: 0.6162  MAE: 0.6243  R²: 0.5480  Train Loss: 0.0442\n",
      "2025-04-07 02:52:33,896 -                                                          \n",
      " Epoch 17\n",
      "2025-04-07 02:52:33,899 -    Pearson: 0.7317  MSE: 0.7151  MAE: 0.6663  R²: 0.4754  Train Loss: 0.0504\n",
      "2025-04-07 02:53:43,854 -                                                          \n",
      " Epoch 18\n",
      "2025-04-07 02:53:43,858 -    Pearson: 0.7387  MSE: 0.6507  MAE: 0.6279  R²: 0.5226  Train Loss: 0.0422\n",
      "2025-04-07 02:54:54,698 -                                                          \n",
      " Epoch 19\n",
      "2025-04-07 02:54:54,701 -    Pearson: 0.7412  MSE: 0.6183  MAE: 0.6298  R²: 0.5464  Train Loss: 0.0363\n",
      "2025-04-07 02:56:01,253 -                                                          \n",
      " Epoch 20\n",
      "2025-04-07 02:56:01,256 -    Pearson: 0.7337  MSE: 0.6761  MAE: 0.6490  R²: 0.5040  Train Loss: 0.0339\n",
      "2025-04-07 02:57:09,811 -                                                          \n",
      " Epoch 21\n",
      "2025-04-07 02:57:09,814 -    Pearson: 0.7527  MSE: 0.6418  MAE: 0.6241  R²: 0.5291  Train Loss: 0.0271\n",
      "2025-04-07 02:57:11,725 -     Saved best model\n",
      "2025-04-07 02:58:18,037 -                                                          \n",
      " Epoch 22\n",
      "2025-04-07 02:58:18,041 -    Pearson: 0.7616  MSE: 0.6227  MAE: 0.6228  R²: 0.5432  Train Loss: 0.0295\n",
      "2025-04-07 02:58:20,036 -     Saved best model\n",
      "2025-04-07 02:59:27,927 -                                                          \n",
      " Epoch 23\n",
      "2025-04-07 02:59:27,930 -    Pearson: 0.7471  MSE: 0.6165  MAE: 0.6174  R²: 0.5478  Train Loss: 0.0248\n",
      "2025-04-07 03:00:35,268 -                                                           \n",
      " Epoch 24\n",
      "2025-04-07 03:00:35,270 -    Pearson: 0.7510  MSE: 0.5943  MAE: 0.6032  R²: 0.5641  Train Loss: 0.0292\n",
      "2025-04-07 03:01:46,045 -                                                          \n",
      " Epoch 25\n",
      "2025-04-07 03:01:46,047 -    Pearson: 0.7549  MSE: 0.5968  MAE: 0.6117  R²: 0.5622  Train Loss: 0.0263\n",
      "2025-04-07 03:02:53,487 -                                                          \n",
      " Epoch 26\n",
      "2025-04-07 03:02:53,490 -    Pearson: 0.7553  MSE: 0.6427  MAE: 0.6175  R²: 0.5285  Train Loss: 0.0209\n",
      "2025-04-07 03:04:00,101 -                                                           \n",
      " Epoch 27\n",
      "2025-04-07 03:04:00,103 -    Pearson: 0.7529  MSE: 0.5934  MAE: 0.6005  R²: 0.5647  Train Loss: 0.0168\n",
      "2025-04-07 03:05:07,819 -                                                           \n",
      " Epoch 28\n",
      "2025-04-07 03:05:07,821 -    Pearson: 0.7515  MSE: 0.6252  MAE: 0.6176  R²: 0.5414  Train Loss: 0.0125\n",
      "2025-04-07 03:06:17,130 -                                                          \n",
      " Epoch 29\n",
      "2025-04-07 03:06:17,131 -    Pearson: 0.7552  MSE: 0.5858  MAE: 0.6024  R²: 0.5703  Train Loss: 0.0134\n",
      "2025-04-07 03:07:23,506 -                                                          \n",
      " Epoch 30\n",
      "2025-04-07 03:07:23,508 -    Pearson: 0.7526  MSE: 0.6274  MAE: 0.6078  R²: 0.5397  Train Loss: 0.0132\n",
      "2025-04-07 03:08:29,098 -                                                           \n",
      " Epoch 31\n",
      "2025-04-07 03:08:29,099 -    Pearson: 0.7606  MSE: 0.5900  MAE: 0.6090  R²: 0.5672  Train Loss: 0.0121\n",
      "2025-04-07 03:09:35,798 -                                                          \n",
      " Epoch 32\n",
      "2025-04-07 03:09:35,800 -    Pearson: 0.7580  MSE: 0.5881  MAE: 0.6008  R²: 0.5686  Train Loss: 0.0074\n",
      "2025-04-07 03:10:42,090 -                                                           \n",
      " Epoch 33\n",
      "2025-04-07 03:10:42,092 -    Pearson: 0.7486  MSE: 0.6081  MAE: 0.6113  R²: 0.5539  Train Loss: 0.0050\n",
      "2025-04-07 03:11:47,132 -                                                          \n",
      " Epoch 34\n",
      "2025-04-07 03:11:47,133 -    Pearson: 0.7542  MSE: 0.6080  MAE: 0.6033  R²: 0.5539  Train Loss: 0.0083\n",
      "2025-04-07 03:12:54,031 -                                                          \n",
      " Epoch 35\n",
      "2025-04-07 03:12:54,034 -    Pearson: 0.7498  MSE: 0.6005  MAE: 0.6130  R²: 0.5595  Train Loss: 0.0086\n",
      "2025-04-07 03:14:01,690 -                                                          \n",
      " Epoch 36\n",
      "2025-04-07 03:14:01,692 -    Pearson: 0.7490  MSE: 0.6197  MAE: 0.6115  R²: 0.5454  Train Loss: 0.0062\n",
      "2025-04-07 03:15:12,354 -                                                          \n",
      " Epoch 37\n",
      "2025-04-07 03:15:12,356 -    Pearson: 0.7513  MSE: 0.6066  MAE: 0.6084  R²: 0.5550  Train Loss: 0.0053\n",
      "2025-04-07 03:16:16,475 -                                                          \n",
      " Epoch 38\n",
      "2025-04-07 03:16:16,476 -    Pearson: 0.7484  MSE: 0.6043  MAE: 0.6137  R²: 0.5567  Train Loss: 0.0039\n",
      "2025-04-07 03:17:22,475 -                                                           \n",
      " Epoch 39\n",
      "2025-04-07 03:17:22,478 -    Pearson: 0.7507  MSE: 0.6066  MAE: 0.6153  R²: 0.5550  Train Loss: 0.0049\n",
      "2025-04-07 03:18:31,304 -                                                          \n",
      " Epoch 40\n",
      "2025-04-07 03:18:31,307 -    Pearson: 0.7460  MSE: 0.6335  MAE: 0.6188  R²: 0.5352  Train Loss: 0.0044\n",
      "2025-04-07 03:19:41,875 -                                                           \n",
      " Epoch 41\n",
      "2025-04-07 03:19:41,876 -    Pearson: 0.7502  MSE: 0.6127  MAE: 0.6151  R²: 0.5505  Train Loss: 0.0027\n",
      "2025-04-07 03:20:47,677 -                                                           \n",
      " Epoch 42\n",
      "2025-04-07 03:20:47,679 -    Pearson: 0.7514  MSE: 0.6136  MAE: 0.6137  R²: 0.5499  Train Loss: 0.0021\n",
      "2025-04-07 03:21:52,464 -                                                           \n",
      " Epoch 43\n",
      "2025-04-07 03:21:52,467 -    Pearson: 0.7509  MSE: 0.6215  MAE: 0.6129  R²: 0.5440  Train Loss: 0.0023\n",
      "2025-04-07 03:22:58,747 -                                                           \n",
      " Epoch 44\n",
      "2025-04-07 03:22:58,750 -    Pearson: 0.7507  MSE: 0.6125  MAE: 0.6155  R²: 0.5507  Train Loss: 0.0036\n",
      "2025-04-07 03:24:05,398 -                                                           \n",
      " Epoch 45\n",
      "2025-04-07 03:24:05,400 -    Pearson: 0.7523  MSE: 0.5997  MAE: 0.6103  R²: 0.5601  Train Loss: 0.0029\n",
      "2025-04-07 03:25:11,882 -                                                           \n",
      " Epoch 46\n",
      "2025-04-07 03:25:11,884 -    Pearson: 0.7497  MSE: 0.6199  MAE: 0.6111  R²: 0.5452  Train Loss: 0.0022\n",
      "2025-04-07 03:26:18,042 -                                                           \n",
      " Epoch 47\n",
      "2025-04-07 03:26:18,045 -    Pearson: 0.7516  MSE: 0.5984  MAE: 0.6093  R²: 0.5610  Train Loss: 0.0014\n",
      "2025-04-07 03:27:26,329 -                                                           \n",
      " Epoch 48\n",
      "2025-04-07 03:27:26,330 -    Pearson: 0.7536  MSE: 0.6034  MAE: 0.6124  R²: 0.5573  Train Loss: 0.0011\n",
      "2025-04-07 03:28:30,472 -                                                           \n",
      " Epoch 49\n",
      "2025-04-07 03:28:30,475 -    Pearson: 0.7481  MSE: 0.6093  MAE: 0.6153  R²: 0.5530  Train Loss: 0.0009\n",
      "2025-04-07 03:29:37,369 -                                                           \n",
      " Epoch 50\n",
      "2025-04-07 03:29:37,370 -    Pearson: 0.7486  MSE: 0.6052  MAE: 0.6117  R²: 0.5560  Train Loss: 0.0014\n",
      "2025-04-07 03:29:37,371 - \n",
      "Training completed at 2025-04-07 03:29:37\n",
      "2025-04-07 03:29:37,371 - Best validation Pearson correlation: 0.7616\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# ============ Configure Logging ============\n",
    "log_filename = f\"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from transformers import AutoTokenizer, WhisperProcessor, WhisperModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# ============ Configure Logging ============\n",
    "log_filename = f\"training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ============ Configs ============\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "AUDIO_DIR = \"audios_train\"\n",
    "CSV_PATH = \"train_with_transcripts_cleaned_filtered.csv\"\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# ============ Load Models ============\n",
    "text_model_name = \"roberta-base\"\n",
    "whisper_model_name = \"openai/whisper-small\"\n",
    "\n",
    "# Load RoBERTa\n",
    "text_tokenizer = AutoTokenizer.from_pretrained(text_model_name)\n",
    "text_model = AutoModel.from_pretrained(text_model_name).to(DEVICE)\n",
    "\n",
    "# Freeze all layers except last two\n",
    "for param in text_model.parameters():\n",
    "    param.requires_grad = False\n",
    "for layer in text_model.encoder.layer[-2:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Load Whisper\n",
    "whisper_processor = WhisperProcessor.from_pretrained(whisper_model_name)\n",
    "whisper_model = WhisperModel.from_pretrained(whisper_model_name).to(DEVICE)\n",
    "whisper_model.eval()\n",
    "for param in whisper_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# ============ Audio Embedding ============\n",
    "failed_audio_count = 0\n",
    "\n",
    "def extract_whisper_embedding(audio_path):\n",
    "    global failed_audio_count\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(audio_path)\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = waveform.mean(dim=0, keepdim=True)\n",
    "        if sr != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
    "            waveform = resampler(waveform)\n",
    "        inputs = whisper_processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs = whisper_model.encoder(inputs.input_features.to(DEVICE))\n",
    "            emb = encoder_outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "        return emb.cpu()\n",
    "    except Exception as e:\n",
    "        failed_audio_count += 1\n",
    "        logging.error(f\"Failed to process {audio_path}: {e}\")\n",
    "        return torch.zeros(768)\n",
    "\n",
    "# ============ Dataset ============\n",
    "class HybridGrammarDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, audio_dir, max_length=256, mean=None, std=None):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.audio_dir = audio_dir\n",
    "        self.max_length = max_length\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row[\"cleaned_text\"] if pd.notna(row[\"cleaned_text\"]) else \"[EMPTY]\"\n",
    "        audio_path = os.path.join(self.audio_dir, row[\"filename\"])\n",
    "\n",
    "        text_inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, \n",
    "                                    max_length=self.max_length, padding=\"max_length\")\n",
    "        input_ids = text_inputs[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = text_inputs[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        audio_emb = extract_whisper_embedding(audio_path)\n",
    "        label = torch.tensor(row[\"label\"], dtype=torch.float)\n",
    "        \n",
    "        if self.mean is not None and self.std is not None:\n",
    "            label = (label - self.mean) / self.std\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"audio_emb\": audio_emb,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "# ============ Model ============\n",
    "class HybridGrammarScorer(nn.Module):\n",
    "    def __init__(self, text_model, hidden_size_text=768, hidden_size_audio=768, combined_hidden=256):\n",
    "        super().__init__()\n",
    "        self.text_model = text_model\n",
    "        self.audio_norm = nn.LayerNorm(hidden_size_audio)\n",
    "        self.text_norm = nn.LayerNorm(hidden_size_text)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size_text + hidden_size_audio, combined_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(combined_hidden),\n",
    "            nn.Linear(combined_hidden, combined_hidden//2),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(combined_hidden//2),\n",
    "            nn.Linear(combined_hidden//2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, audio_emb):\n",
    "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_emb = text_output.last_hidden_state[:, 0, :]\n",
    "        text_emb = self.text_norm(text_emb)\n",
    "        audio_emb = self.audio_norm(audio_emb)\n",
    "        combined = torch.cat([text_emb, audio_emb], dim=1)\n",
    "        return self.fc(combined)\n",
    "\n",
    "# ============ Prepare Data ============\n",
    "full_df = pd.read_csv(CSV_PATH)\n",
    "train_df, val_df = train_test_split(full_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mean = train_df[\"label\"].mean()\n",
    "train_std = train_df[\"label\"].std()\n",
    "\n",
    "train_dataset = HybridGrammarDataset(train_df, text_tokenizer, AUDIO_DIR, \n",
    "                                   mean=train_mean, std=train_std)\n",
    "val_dataset = HybridGrammarDataset(val_df, text_tokenizer, AUDIO_DIR,\n",
    "                                  mean=train_mean, std=train_std)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# ============ Train ============\n",
    "model = HybridGrammarScorer(text_model).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "best_pearson = -1\n",
    "\n",
    "logging.info(f\"Failed audio files during dataset creation: {failed_audio_count}\")\n",
    "logging.info(f\"Training started at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "logging.info(f\"Training parameters: BATCH_SIZE={BATCH_SIZE}, EPOCHS={EPOCHS}\")\n",
    "logging.info(f\"Label stats: Mean={train_mean:.2f}, Std={train_std:.2f}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    model.text_model.eval()\n",
    "    total_loss = 0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} Training\", leave=False)\n",
    "\n",
    "    for batch in train_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        audio_emb = batch[\"audio_emb\"].to(DEVICE)\n",
    "        labels = batch[\"label\"].to(DEVICE).unsqueeze(1)\n",
    "\n",
    "        preds = model(input_ids, attention_mask, audio_emb)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            audio_emb = batch[\"audio_emb\"].to(DEVICE)\n",
    "            labels = batch[\"label\"].to(DEVICE).unsqueeze(1)\n",
    "\n",
    "            preds = model(input_ids, attention_mask, audio_emb)\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    # Denormalize\n",
    "    all_preds = np.array(all_preds) * train_std + train_mean\n",
    "    all_labels = np.array(all_labels) * train_std + train_mean\n",
    "\n",
    "    pearson_corr, _ = pearsonr(all_preds, all_labels)\n",
    "    mse = mean_squared_error(all_labels, all_preds)\n",
    "    mae = mean_absolute_error(all_labels, all_preds)\n",
    "    r2 = r2_score(all_labels, all_preds)\n",
    "\n",
    "    logging.info(f\"\\n Epoch {epoch+1}\")\n",
    "    logging.info(f\"   Pearson: {pearson_corr:.4f}  MSE: {mse:.4f}  MAE: {mae:.4f}  R²: {r2:.4f}  Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if pearson_corr > best_pearson:\n",
    "        best_pearson = pearson_corr\n",
    "        torch.save(model.state_dict(), \"best_whisper_hybrid_model.pt\")\n",
    "        logging.info(\"    Saved best model\")\n",
    "\n",
    "logging.info(f\"\\nTraining completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "logging.info(f\"Best validation Pearson correlation: {best_pearson:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Making predictions: 100%|██████████| 25/25 [00:30<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submission.csv\n",
      "Sample predictions:\n",
      "         filename     label\n",
      "0   audio_706.wav  3.723375\n",
      "1   audio_800.wav  3.642146\n",
      "2    audio_68.wav  3.088547\n",
      "3  audio_1267.wav  2.670847\n",
      "4   audio_683.wav  2.520207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ============ Configs ============\n",
    "TEST_CSV_PATH = \"test_with_transcripts_cleaned_filtered.csv\"  # Path to your test CSV\n",
    "TEST_AUDIO_DIR = \"audios_test\"  # Path to test audio files\n",
    "MODEL_PATH = \"best_whisper_hybrid_model.pt\"\n",
    "SUBMISSION_PATH = \"submission.csv\"\n",
    "\n",
    "# ============ Load Test Data ============\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, audio_dir, max_length=256, mean=None, std=None):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.audio_dir = audio_dir\n",
    "        self.max_length = max_length\n",
    "        self.mean = mean  # Use the same mean/std as training\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = row[\"cleaned_text\"] if \"cleaned_text\" in row and pd.notna(row[\"cleaned_text\"]) else \"[EMPTY]\"\n",
    "        audio_path = os.path.join(self.audio_dir, row[\"filename\"])\n",
    "\n",
    "        text_inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, \n",
    "                                   max_length=self.max_length, padding=\"max_length\")\n",
    "        input_ids = text_inputs[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = text_inputs[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        audio_emb = extract_whisper_embedding(audio_path)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"audio_emb\": audio_emb,\n",
    "            \"filename\": row[\"filename\"]\n",
    "        }\n",
    "\n",
    "# ============ Load Model ============\n",
    "model = HybridGrammarScorer(text_model).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# ============ Make Predictions ============\n",
    "test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "test_dataset = TestDataset(test_df, text_tokenizer, TEST_AUDIO_DIR, \n",
    "                         mean=train_mean, std=train_std)  # Use training stats\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Making predictions\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        audio_emb = batch[\"audio_emb\"].to(DEVICE)\n",
    "        \n",
    "        preds = model(input_ids, attention_mask, audio_emb)\n",
    "        preds = preds.cpu().numpy().flatten()\n",
    "        preds = preds * train_std + train_mean  # Denormalize\n",
    "        \n",
    "        predictions.extend(preds)\n",
    "        filenames.extend(batch[\"filename\"])\n",
    "\n",
    "# ============ Save Predictions ============\n",
    "submission_df = pd.DataFrame({\n",
    "    \"filename\": filenames,\n",
    "    \"label\": predictions\n",
    "})\n",
    "\n",
    "# Ensure predictions are within reasonable bounds (adjust if needed)\n",
    "submission_df[\"label\"] = submission_df[\"label\"].clip(lower=1, upper=5)  # Example for 1-5 scale\n",
    "\n",
    "submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"Predictions saved to {SUBMISSION_PATH}\")\n",
    "print(f\"Sample predictions:\\n{submission_df.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_TTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
